{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Builiding a local RAG Agent for VisionOS Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in modules and setup Langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langsmith import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = str(os.getenv(\"LANGCHAIN_API_KEY\"))\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"custom-rag-project\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model: Mistral 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is an example of how you can create a wrapper function in JavaScript that tests for errors and logs them using the `try-catch` block:\n",
      "\n",
      "```javascript\n",
      "function wrapFunction(func, message) {\n",
      "  return function() {\n",
      "    try {\n",
      "      return func.apply(this, arguments);\n",
      "    } catch (error) {\n",
      "      console.log(`[${new Date().toLocaleString()}] Error: ${message} - ${error.message}`);\n",
      "      throw error;\n",
      "    }\n",
      "  };\n",
      "}\n",
      "``\n",
      "\n",
      "// Usage example\n",
      "function add(x, y) {\n",
      "  return x + y;\n",
      "}\n",
      "\n",
      "const wrappedAdd = wrapFunction(add, 'Error message: add function');\n",
      "const result = wrappedAdd(5, 10); // No error, the function works as intended\n",
      "\n",
      "try {\n",
      "  const wrongFunction = () => {};\n",
      "  const result = wrongFunction();\n",
      "} catch (error) {\n",
      "  // This block will not be executed since there is no error in the previous code.\n",
      "  console.log('An error occurred:', error.message);\n",
      "}\n",
      "\n",
      "const wrappedWrongFunction = wrapFunction(wrongFunction, 'Error message: wrongFunction');\n",
      "try {\n",
      "  wrappedWrongFunction();\n",
      "} catch (error) {\n",
      "  console.log(`[${new Date().toLocaleString()}] Error: ${error.message}`);\n",
      "}\n",
      "```\n",
      "\n",
      "In the example above, `wrapFunction` is a higher-order function that accepts a function and a message as arguments. The returned function will wrap the given function using the `try-catch` block. When an error occurs within the wrapped function, it logs the error message along with the current date and time before rethrowing the error.\n"
     ]
    }
   ],
   "source": [
    "# supports many more optional parameters. Hover on your `ChatOllama(...)`\n",
    "# class to view the latest available supported parameters\n",
    "\n",
    "# Load the LangSmith Client and Test Run\n",
    "client = Client()\n",
    "\n",
    "model = \"mistral:instruct\"\n",
    "llm = ChatOllama(model=model)\n",
    "prompt = ChatPromptTemplate.from_template(\"Write code to {topic}\")\n",
    "\n",
    "# using LangChain Expressive Language chain syntax\n",
    "# learn more about the LCEL on\n",
    "# https://python.langchain.com/docs/expression_language/why\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# for brevity, response is printed in terminal\n",
    "# You can use LangServe to deploy your application for production\n",
    "print(chain.invoke({\"topic\": \"create a wrapper function that tests for errors and logs them\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#open json file\n",
    "with open('/Users/seangorman/code-projects/rag-project/scraped_docs_updated_again.json') as f:\n",
    "  data = json.load(f)\n",
    "\n",
    "data\n",
    "\n",
    "#for each dict in douments, add each element in code examples to the end of content, have each element in code examples be a new paragraph\n",
    "for i in range(len(data['documents'])):\n",
    "    for j in range(len(data['documents'][i]['code_examples'])):\n",
    "        data['documents'][i]['content'] += '\\n\\n\\n\\n' + data['documents'][i]['code_examples'][j]\n",
    "\n",
    "#open json file\n",
    "with open('data_docs.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_docs.json') as f:\n",
    "  data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Docs\n",
    "\n",
    "These documents were scraped using selenium and beautiful soup. Here, I'm counting up the total number of tokens in our document to see what we're working with. Mistral 7b can handle up to 32K tokens in it's context window, so we'll need to account for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tiktoken\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "import json\n",
    "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
    "\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "#load in scraped_docs_updates.json\n",
    "with open(\"scraped_docs_updated_again.json\", \"r\") as file:\n",
    "    docs = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://developer.apple.com/documentation/visionos/world',\n",
       " 'title': 'Hello World | Apple Developer Documentation',\n",
       " 'content': 'App construction Creating your first visionOS app Adding 3D content to your app Creating fully immersive experiences in your app Drawing sharp layer-based content in visionOS Design Designing for visionOS Adopting best practices for privacy and user preferences Improving accessibility support in your visionOS app SwiftUI Hello World Presenting windows and spaces Positioning and sizing windows RealityKit and Reality Composer Pro Swift Splash Diorama Understanding RealityKit’s modular architecture Designing RealityKit content with Reality Composer Pro Capturing screenshots and video from Apple Vision Pro for 2D viewing ARKit Happy Beam Setting up access to ARKit data Incorporating real-world surroundings in an immersive experience Placing content on detected planes Tracking specific points in world space   You can use visionOS scene types and styles to share information in fun and compelling ways. Features like volumes and immersive spaces let you put interactive virtual objects into people’s environments, or put people into a virtual environment. Hello World uses these tools to teach people about the Earth — the planet we call home. The app shows how the Earth’s tilt creates the seasons, how objects move as they orbit the Earth, and how Earth appears from space. The app uses SwiftUI to define its interface, including both 2D and 3D elements. To create, customize, and manage 3D models and effects, it also relies on the RealityKit framework and Reality Composer Pro. Hello World constructs the scene that it displays at launch — the first scene that appears in the WorldApp structure — using a WindowGroup: Like other platforms — for example, macOS and iOS — visionOS displays a window group as a familiar-looking window. In visionOS, people can resize and move windows around the Shared Space. Even if your app offers a sophisticated 3D experience, a window is a great starting point for an app because it eases people into the experience. It’s also a good place to provide instructions or controls. Tip This particular window group uses the plain window style to maintain control over the glass background effect that visionOS would otherwise automatically add. After you watch a brief introductory animation that shows the text Hello World typing in, the Modules view that defines the primary scene’s content presents options to explore different aspects of the world. This view contains a table of contents at the root of a NavigationStack: A visionOS navigation stack has the same behavior that it has in other platforms. When it first appears, the stack displays its root view. When someone chooses an embedded NavigationLink, the stack draws a new view and displays a back button in the toolbar. When someone taps the back button, the stack restores the previous view.  The trailing closure of the navigationDestination(for:destination:) view modifier in the code above displays a view when someone activates a link based on a module input that comes from the corresponding link’s initializer: The possible module values come from a custom Module enumeration: The globe module opens with a few facts about the Earth in the main window next to a decorative, flat image that supports the content. To help people understand even more, the module includes a button titled View Globe that opens a 3D interactive globe in a new window.  To be able to open multiple scene types, Hello World includes the UIApplicationSceneManifest key in its Information Property List file. The value for this key is a dictionary that includes the UIApplicationSupportsMultipleScenes key with a value of true: With the key in place, the app makes use of a second WindowGroup in its App declaration. This new window group uses the Globe view as its content: This window group creates a volume — which is a container that has three dimensions and behaves like a transparent box — because Hello World uses the volumetric window style scene modifier. People can move this box around the Shared Space like they move other window types, and the content remains fixed inside. The defaultSize(width:height:depth:in:) modifier specifies a size for the volume in meters, including a depth dimension. The Globe view inside the volume contains 3D content, but is still just a SwiftUI view. It contains two elements in a ZStack: a subview that draws a model of the Earth, and another that provides a control panel that people can use to configure the model’s appearance. The globe module presents a View Globe button that people can tap to display or dismiss the volume, depending on the current state. Hello World achieves this behavior by creating a Toggle with the button style, and embedding it in a custom GlobeToggle view.  When someone taps the toggle, the isShowingGlobe state changes, and the onChange(of:initial:_:) modifier calls the openWindow or dismissWindow action to open or dismiss the volume, respectively. The view gets these actions from the environment and uses an identifier that matches the volume’s identifier. You use windows in visionOS the same way you do in other platforms. But even 2D windows in visionOS provide a small amount of depth you can use to create 3D effects — like elements that appear in front of other elements. Hello World takes advantage of this depth to present small models inline with 2D content. The app’s second module, Objects in Orbit, provides information about objects that go around the Earth, like the Moon and artificial satellites. To give a sense of what these objects look like, the module displays 3D models of these items directly inside the window.  Hello World loads these models from the asset bundle using a Model3D structure inside a custom ItemView. The view scales and positions the model to fit the available space, and applies optional orientation adjustments: The app uses this ItemView once for each model, placing each in an overlay that only becomes visible based on the current selection. For example, the following overlay displays the satellite model with a small amount of tilt in the x-axis and z-axis: The VStack that contains the models also contains a Picker that people use to select a model to view: When you add 3D effects to a 2D window, keep this guidance in mind: Don’t overdo it. These kinds of effects add interest, but can unintentionally obscure important controls or information as people view the window from different directions. Ensure that elements don’t exceed the available depth. Excess depth causes elements to clip. Account for any position or orientation changes that might occur after initial placement. Avoid models intersecting with the backing glass. Again, account for potential movement after initial placement. People can visualize how satellites move around the Earth because the app’s orbit module displays the Earth, the Moon, and a communications satellite together as a single system. People can move the system anywhere in their environment or resize it using standard gestures. They can also move themselves around the system to get different perspectives.  Note To learn about designing with gestures in visionOS, read Gestures in Human Interface Guidelines. To create this visualization, the app displays the Orbit view — which contains a single RealityView that models the entire system — in an ImmersiveSpace scene with the mixed immersion style: As with any secondary scene in a visionOS app, this scene depends on having the UIApplicationSupportsMultipleScenes key in the Information Property List file. The app also opens and closes the space using a toggle view that resembles the one used for the globe: There are a few key differences from the version that appears in the section Open and dismiss the globe volume: OrbitToggle uses openImmersiveSpace and dismissImmersiveSpace from the environment, rather than the window equivalents. The dismiss action in this case doesn’t require an identifier, because people can only open one space at a time, even across apps. The open and dismiss actions for spaces operate asynchronously, and so they appear inside a Task. The app’s final module gives people a sense of the Earth’s place in the solar system. Like other modules, this one includes information and a decorative image next to a button that leads to another visualization — in this case so people can experience Earth from space. When a person taps the button, the app takes over the entire display and shows stars in all directions. The Earth appears directly in front, the Moon to the right, and the Sun to the left. The main window also shows a small control panel that people can use to exit the fully immersive experience.  Tip People can always close the currently open immersive space by pressing the device’s Digital Crown, but it’s typically useful when you provide a built-in mechanism to maintain control of the experience within your app. The app uses another immersive space scene for this module, but here with the full immersion style that turns off the passthrough video: This scene depends on the same UIApplicationSupportsMultipleScenes key that other secondary scenes do, and is activated by a SolarSystemToggle that’s similar to the ones that the app uses for the other scenes: This control appears in the main window to provide a way to begin the fully immersive experience, and separately in the control panel as a way to exit the experience. Because the app uses this control as two distinct buttons rather than as a toggle in one location, it’s composed of a Button with behavior that changes depending on the app state rather than as a toggle with a button style. To reuse the main window for the solar system controls, Hello World places both the navigation stack and the controls in a ZStack, and then sets the opacity of each to ensure that only one appears at a time:',\n",
       " 'code_examples': ['WindowGroup(\"Hello World\", id: \"modules\") {\\n    Modules()\\n        .environment(model)\\n}\\n.windowStyle(.plain)\\n',\n",
       "  'NavigationStack(path: $model.navigationPath) {\\n    TableOfContents()\\n        .navigationDestination(for: Module.self) { module in\\n            ModuleDetail(module: module)\\n                .navigationTitle(module.eyebrow)\\n        }\\n}\\n',\n",
       "  \"NavigationLink(value: module) { /* The link's label. */ }\\n\",\n",
       "  'enum Module: String, Identifiable, CaseIterable, Equatable {\\n    case globe, orbit, solar\\n    // ...\\n}\\n',\n",
       "  '<key>UIApplicationSceneManifest</key>\\n<dict>\\n    <key>UIApplicationSupportsMultipleScenes</key>\\n    <true/>\\n    <key>UISceneConfigurations</key>\\n    <dict/>\\n</dict>\\n',\n",
       "  'WindowGroup(id: Module.globe.name) {\\n    Globe()\\n        .environment(model)\\n}\\n.windowStyle(.volumetric)\\n.defaultSize(width: 0.6, height: 0.6, depth: 0.6, in: .meters)\\n',\n",
       "  'struct GlobeToggle: View {\\n    @Environment(ViewModel.self) private var model\\n    @Environment(\\\\.openWindow) private var openWindow\\n    @Environment(\\\\.dismissWindow) private var dismissWindow\\n\\n\\n    var body: some View {\\n        @Bindable var model = model\\n\\n\\n        Toggle(Module.globe.callToAction, isOn: $model.isShowingGlobe)\\n            .onChange(of: model.isShowingGlobe) { _, isShowing in\\n                if isShowing {\\n                    openWindow(id: Module.globe.name)\\n                } else {\\n                    dismissWindow(id: Module.globe.name)\\n                }\\n            }\\n            .toggleStyle(.button)\\n    }\\n}\\n',\n",
       "  'private struct ItemView: View {\\n    var item: Item\\n    var orientation: SIMD3<Double> = .zero\\n\\n\\n    var body: some View {\\n        Model3D(named: item.name, bundle: worldAssetsBundle) { model in\\n            model.resizable()\\n                .scaledToFit()\\n                .rotation3DEffect(\\n                    Rotation3D(\\n                        eulerAngles: .init(angles: orientation, order: .xyz)\\n                    )\\n                )\\n                .frame(depth: modelDepth)\\n                .offset(z: -modelDepth / 2)\\n        } placeholder: {\\n            ProgressView()\\n                .offset(z: -modelDepth * 0.75)\\n        }\\n    }\\n}\\n',\n",
       "  '.overlay {\\n    ItemView(item: .satellite, orientation: [0.15, 0, 0.15])\\n        .opacity(selection == .satellite ? 1 : 0)\\n}\\n',\n",
       "  'Picker(\"Satellite\", selection: $selection) {\\n    ForEach(Item.allCases) { item in\\n        Text(item.name)\\n    }\\n}\\n.pickerStyle(.segmented)\\n',\n",
       "  'ImmersiveSpace(id: Module.orbit.name) {\\n    Orbit()\\n        .environment(model)\\n}\\n.immersionStyle(selection: $orbitImmersionStyle, in: .mixed)\\n',\n",
       "  'struct OrbitToggle: View {\\n    @Environment(ViewModel.self) private var model\\n    @Environment(\\\\.openImmersiveSpace) private var openImmersiveSpace\\n    @Environment(\\\\.dismissImmersiveSpace) private var dismissImmersiveSpace\\n\\n\\n    var body: some View {\\n        @Bindable var model = model\\n\\n\\n        Toggle(Module.orbit.callToAction, isOn: $model.isShowingOrbit)\\n            .onChange(of: model.isShowingOrbit) { _, isShowing in\\n                Task {\\n                    if isShowing {\\n                        await openImmersiveSpace(id: Module.orbit.name)\\n                    } else {\\n                        await dismissImmersiveSpace()\\n                    }\\n                }\\n            }\\n            .toggleStyle(.button)\\n    }\\n}\\n',\n",
       "  'ImmersiveSpace(id: Module.solar.name) {\\n    SolarSystem()\\n        .environment(model)\\n}\\n.immersionStyle(selection: $solarImmersionStyle, in: .full)\\n',\n",
       "  'struct SolarSystemToggle: View {\\n    @Environment(ViewModel.self) private var model\\n    @Environment(\\\\.openImmersiveSpace) private var openImmersiveSpace\\n    @Environment(\\\\.dismissImmersiveSpace) private var dismissImmersiveSpace\\n\\n\\n    var body: some View {\\n        Button {\\n            Task {\\n                if model.isShowingSolar {\\n                    await dismissImmersiveSpace()\\n                } else {\\n                    await openImmersiveSpace(id: Module.solar.name)\\n                }\\n            }\\n        } label: {\\n            if model.isShowingSolar {\\n                Label(\\n                    \"Exit the Solar System\",\\n                    systemImage: \"arrow.down.right.and.arrow.up.left\")\\n            } else {\\n                Text(Module.solar.callToAction)\\n            }\\n        }\\n    }\\n}\\n',\n",
       "  'ZStack {\\n    SolarSystemControls()\\n        .opacity(model.isShowingSolar ? 1 : 0)\\n\\n\\n    NavigationStack(path: $model.navigationPath) {\\n        // ...\\n    }\\n    .opacity(model.isShowingSolar ? 0 : 1)\\n}\\n.animation(.default, value: model.isShowingSolar)\\n']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs['documents'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_texts = [d['content'] for d in docs['documents']]\n",
    "docs_code = [d['code_examples'] for d in docs['documents']]\n",
    "combined_docs = [d['content'] + \" \" + \" \".join(d['code_examples']) for d in docs['documents']]\n",
    "# Calculate the number of tokens for each document\n",
    "counts = [num_tokens_from_string(d, \"cl100k_base\") for d in combined_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the histogram of token counts\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(counts, bins=30, color=\"blue\", edgecolor=\"black\", alpha=0.7)\n",
    "plt.title(\"Histogram of Token Counts\")\n",
    "plt.xlabel(\"Token Count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(axis=\"y\", alpha=0.75)\n",
    "\n",
    "# Display the histogram\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of counts: 81966\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of counts: {sum(counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "\n",
    "loader = JSONLoader(\n",
    "    file_path='scraped_docs_updated_again.json', #data_docs\n",
    "    jq_schema=\".documents[]\",\n",
    "    content_key=\"content\",\n",
    "    #is_content_key_jq_parsable=True,\n",
    "    )\n",
    "\n",
    "data = loader.load()\n",
    "data\n",
    "\n",
    "\n",
    "urls = JSONLoader(\n",
    "    file_path='scraped_docs_updated_again.json',\n",
    "    jq_schema=\".documents[]\",\n",
    "    content_key=\"url\",\n",
    "    )\n",
    "\n",
    "titles = JSONLoader(\n",
    "    file_path='scraped_docs_updated_again.json',\n",
    "    jq_schema=\".documents[]\",\n",
    "    content_key=\"title\",\n",
    "    )\n",
    "\n",
    "titles = titles.load()\n",
    "urls = urls.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://developer.apple.com/documentation/visionos',\n",
       " 'title': 'visionOS | Apple Developer Documentation',\n",
       " 'seq_num': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#update the metadata function to include the title and url\n",
    "def update_metadata(record, titles, urls):\n",
    "\n",
    "    sources = [urls[i].page_content for i in range(len(urls))],\n",
    "    titles = [titles[i].page_content for i in range(len(titles))]\n",
    "\n",
    "    \n",
    "    for i in range(len(record)):\n",
    "        seq_count = 1\n",
    "        record[i].metadata = {\"source\": sources[0][i], \"title\": titles[i], 'seq_num': seq_count}\n",
    "        seq_count += 1\n",
    "    return record\n",
    "\n",
    "update_metadata(data, titles, urls)\n",
    "\n",
    "data[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Global Nav Open MenuGlobal Nav Close Menu Apple Developer Apple Developer News Discover Design Develop Distribute Support Account  Downloads Documentation Videos Forums Xcode App construction Creating your first visionOS app Adding 3D content to your app Creating fully immersive experiences in your app Drawing sharp layer-based content in visionOS Design Designing for visionOS Adopting best practices for privacy and user preferences Improving accessibility support in your visionOS app SwiftUI Hello World Presenting windows and spaces Positioning and sizing windows RealityKit and Reality Composer Pro Swift Splash Diorama Understanding RealityKit’s modular architecture Designing RealityKit content with Reality Composer Pro Capturing screenshots and video from Apple Vision Pro for 2D viewing ARKit Happy Beam Setting up access to ARKit data Incorporating real-world surroundings in an immersive experience Placing content on detected planes Tracking specific points in world space  / visionOS API Changes: None visionOS is the operating system that powers Apple Vision Pro. Use visionOS together with familiar tools and technologies to build immersive apps and games for spatial computing.  Developing for visionOS requires a Mac with Apple silicon. Create new apps using SwiftUI to take full advantage of the spectrum of immersion available in visionOS. If you have an existing iPad or iPhone app, add the visionOS destination to your app’s target to gain access to the standard system appearance, and add platform-specific features to create a compelling experience. To provide continuous access to your content in the meantime, deliver a compatible version of your app that runs in visionOS. Start with a familiar window-based experience to introduce people to your content. From there, add SwiftUI scene types specific to visionOS, such as volumes and spaces. These scene types let you incorporate depth, 3D objects, and immersive experiences. Build your app’s 3D content with RealityKit and Reality Composer Pro, and display it with a RealityView. In an immersive experience, use ARKit to integrate your content with the person’s surroundings.  People can select an element by looking at it and tapping their fingers together. They can also pinch, drag, zoom, and rotate objects using specific hand gestures. SwiftUI provides built-in support for these standard gestures, so rely on them for most of your app’s input. When you want to go beyond the standard gestures, use ARKit to create custom gestures. Tap to select Pinch to rotate Manipulate objects Create custom gestures Explore the core concepts for all visionOS apps with Hello World. Understand how to detect custom gestures using ARKit with Happy Beam. Discover streaming 2D and stereoscopic media with Destination Video. And learn how to build 3D scenes with RealityKit and Reality Composer Pro with Diorama and Swift Splash. visionOS Overview Expand your app into immersive spaces Explore new kinds of interaction Dive into featured sample apps Topics Developer Documentation iOS iPadOS macOS tvOS visionOS watchOS Swift SwiftUI Swift Playgrounds TestFlight Xcode Xcode Cloud SF Symbols Accessibility Accessories App Extension App Store Audio & Video Augmented Reality Business Design Distribution Education Fonts Games Health & Fitness In-App Purchase Localization Maps & Location Machine Learning Security Safari & Web  Documentation Curriculum Downloads Forums Videos Support Articles Contact Us Bug Reporting System Status Apple Developer App Store Connect Certificates, IDs, & Profiles Feedback Assistant Apple Developer Program Apple Developer Enterprise Program App Store Small Business Program MFi Program News Partner Program Video Partner Program Security Bounty Program Security Research Device Program Events Overview App Accelerators App Store Awards Apple Design Awards Apple Developer Academies Entrepreneur Camp WWDC', metadata={'source': 'https://developer.apple.com/documentation/visionos', 'title': 'visionOS | Apple Developer Documentation', 'seq_num': 1})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Vecstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained('nomic-ai/nomic-embed-text-v1.5', trust_remote_code=True, safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 23 key-value pairs and 112 tensors from nomic-embed-text-v1.5.Q2_K.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = nomic-bert\n",
      "llama_model_loader: - kv   1:                               general.name str              = nomic-embed-text-v1.5\n",
      "llama_model_loader: - kv   2:                     nomic-bert.block_count u32              = 12\n",
      "llama_model_loader: - kv   3:                  nomic-bert.context_length u32              = 2048\n",
      "llama_model_loader: - kv   4:                nomic-bert.embedding_length u32              = 768\n",
      "llama_model_loader: - kv   5:             nomic-bert.feed_forward_length u32              = 3072\n",
      "llama_model_loader: - kv   6:            nomic-bert.attention.head_count u32              = 12\n",
      "llama_model_loader: - kv   7:    nomic-bert.attention.layer_norm_epsilon f32              = 0.000000\n",
      "llama_model_loader: - kv   8:                          general.file_type u32              = 10\n",
      "llama_model_loader: - kv   9:                nomic-bert.attention.causal bool             = false\n",
      "llama_model_loader: - kv  10:                    nomic-bert.pooling_type u32              = 1\n",
      "llama_model_loader: - kv  11:                  nomic-bert.rope.freq_base f32              = 1000.000000\n",
      "llama_model_loader: - kv  12:            tokenizer.ggml.token_type_count u32              = 2\n",
      "llama_model_loader: - kv  13:                tokenizer.ggml.bos_token_id u32              = 101\n",
      "llama_model_loader: - kv  14:                tokenizer.ggml.eos_token_id u32              = 102\n",
      "llama_model_loader: - kv  15:                       tokenizer.ggml.model str              = bert\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.tokens arr[str,30522]   = [\"[PAD]\", \"[unused0]\", \"[unused1]\", \"...\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.scores arr[f32,30522]   = [-1000.000000, -1000.000000, -1000.00...\n",
      "llama_model_loader: - kv  18:                  tokenizer.ggml.token_type arr[i32,30522]   = [3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 100\n",
      "llama_model_loader: - kv  20:          tokenizer.ggml.seperator_token_id u32              = 102\n",
      "llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  22:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   51 tensors\n",
      "llama_model_loader: - type q2_K:   37 tensors\n",
      "llama_model_loader: - type q3_K:   24 tensors\n",
      "llm_load_vocab: mismatch in special tokens definition ( 7104/30522 vs 5/30522 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = nomic-bert\n",
      "llm_load_print_meta: vocab type       = WPM\n",
      "llm_load_print_meta: n_vocab          = 30522\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 2048\n",
      "llm_load_print_meta: n_embd           = 768\n",
      "llm_load_print_meta: n_head           = 12\n",
      "llm_load_print_meta: n_head_kv        = 12\n",
      "llm_load_print_meta: n_layer          = 12\n",
      "llm_load_print_meta: n_rot            = 64\n",
      "llm_load_print_meta: n_embd_head_k    = 64\n",
      "llm_load_print_meta: n_embd_head_v    = 64\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 768\n",
      "llm_load_print_meta: n_embd_v_gqa     = 768\n",
      "llm_load_print_meta: f_norm_eps       = 1.0e-12\n",
      "llm_load_print_meta: f_norm_rms_eps   = 0.0e+00\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 3072\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: pooling type     = 1\n",
      "llm_load_print_meta: rope type        = 2\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 2048\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 137M\n",
      "llm_load_print_meta: model ftype      = Q2_K - Medium\n",
      "llm_load_print_meta: model params     = 136.73 M\n",
      "llm_load_print_meta: model size       = 46.35 MiB (2.84 BPW) \n",
      "llm_load_print_meta: general.name     = nomic-embed-text-v1.5\n",
      "llm_load_print_meta: BOS token        = 101 '[CLS]'\n",
      "llm_load_print_meta: EOS token        = 102 '[SEP]'\n",
      "llm_load_print_meta: UNK token        = 100 '[UNK]'\n",
      "llm_load_print_meta: SEP token        = 102 '[SEP]'\n",
      "llm_load_print_meta: PAD token        = 0 '[PAD]'\n",
      "llm_load_tensors: ggml ctx size =    0.04 MiB\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/13 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =    46.35 MiB\n",
      "..................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: freq_base  = 1000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =    18.00 MiB\n",
      "llama_new_context_with_model: KV self size  =   18.00 MiB, K (f16):    9.00 MiB, V (f16):    9.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =     3.51 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    21.00 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 1\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 0 | ARM_FMA = 0 | F16C = 0 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.seperator_token_id': '102', 'tokenizer.ggml.unknown_token_id': '100', 'tokenizer.ggml.model': 'bert', 'tokenizer.ggml.eos_token_id': '102', 'general.quantization_version': '2', 'tokenizer.ggml.token_type_count': '2', 'tokenizer.ggml.bos_token_id': '101', 'nomic-bert.rope.freq_base': '1000.000000', 'nomic-bert.embedding_length': '768', 'nomic-bert.attention.causal': 'false', 'general.file_type': '10', 'nomic-bert.attention.layer_norm_epsilon': '0.000000', 'nomic-bert.attention.head_count': '12', 'nomic-bert.feed_forward_length': '3072', 'nomic-bert.context_length': '2048', 'nomic-bert.block_count': '12', 'nomic-bert.pooling_type': '1', 'general.name': 'nomic-embed-text-v1.5', 'general.architecture': 'nomic-bert'}\n",
      "Using fallback chat format: None\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain_community.embeddings import LlamaCppEmbeddings\n",
    "\n",
    "\n",
    "# Embed and index Nomic v1.5\n",
    "embd_model_path = \"nomic-embed-text-v1.5.Q2_K.gguf\"\n",
    "embedding = LlamaCppEmbeddings(model_path=embd_model_path, n_batch=512, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    4910.96 ms /   512 tokens (    9.59 ms per token,   104.26 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    5082.50 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    4891.39 ms /   512 tokens (    9.55 ms per token,   104.67 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    4894.35 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    3965.98 ms /   512 tokens (    7.75 ms per token,   129.10 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    3969.12 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    3711.46 ms /   512 tokens (    7.25 ms per token,   137.95 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    3714.60 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    5461.08 ms /   512 tokens (   10.67 ms per token,    93.75 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    5466.38 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    3762.24 ms /   512 tokens (    7.35 ms per token,   136.09 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    3770.00 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    3675.73 ms /   512 tokens (    7.18 ms per token,   139.29 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    3680.43 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    4113.48 ms /   512 tokens (    8.03 ms per token,   124.47 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    4118.20 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    3789.37 ms /   512 tokens (    7.40 ms per token,   135.11 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    3800.56 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    4898.86 ms /   512 tokens (    9.57 ms per token,   104.51 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    4904.98 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    4692.37 ms /   512 tokens (    9.16 ms per token,   109.11 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    4699.51 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    5045.04 ms /   512 tokens (    9.85 ms per token,   101.49 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    5051.25 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    3872.38 ms /   512 tokens (    7.56 ms per token,   132.22 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    3877.85 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    3986.41 ms /   512 tokens (    7.79 ms per token,   128.44 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    3994.95 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    9140.97 ms /   512 tokens (   17.85 ms per token,    56.01 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    9154.08 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    4999.54 ms /   512 tokens (    9.76 ms per token,   102.41 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    5031.75 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    5334.67 ms /   512 tokens (   10.42 ms per token,    95.98 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    5337.92 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    3629.65 ms /   512 tokens (    7.09 ms per token,   141.06 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    3633.13 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    3618.81 ms /   512 tokens (    7.07 ms per token,   141.48 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    3622.69 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    3915.49 ms /   512 tokens (    7.65 ms per token,   130.76 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    3918.35 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    3780.16 ms /   512 tokens (    7.38 ms per token,   135.44 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    3784.73 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    3952.26 ms /   512 tokens (    7.72 ms per token,   129.55 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    3958.08 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    5519.34 ms /   512 tokens (   10.78 ms per token,    92.76 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    5524.60 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    6214.31 ms /   512 tokens (   12.14 ms per token,    82.39 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    6219.42 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    4716.37 ms /   512 tokens (    9.21 ms per token,   108.56 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    4721.53 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    4729.36 ms /   512 tokens (    9.24 ms per token,   108.26 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    4741.71 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    4593.92 ms /   512 tokens (    8.97 ms per token,   111.45 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    4598.69 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    9851.31 ms /   512 tokens (   19.24 ms per token,    51.97 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    9870.79 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    5747.16 ms /   512 tokens (   11.22 ms per token,    89.09 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    5767.90 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    5403.30 ms /   512 tokens (   10.55 ms per token,    94.76 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    5410.02 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    4673.81 ms /   512 tokens (    9.13 ms per token,   109.55 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    4681.58 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    4104.27 ms /   512 tokens (    8.02 ms per token,   124.75 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    4110.64 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    5220.56 ms /   512 tokens (   10.20 ms per token,    98.07 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    5227.34 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    7136.19 ms /   512 tokens (   13.94 ms per token,    71.75 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    7153.05 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    5856.05 ms /   512 tokens (   11.44 ms per token,    87.43 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    5864.30 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    4477.53 ms /   512 tokens (    8.75 ms per token,   114.35 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    4480.80 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    4570.77 ms /   512 tokens (    8.93 ms per token,   112.02 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    4573.97 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    3893.22 ms /   512 tokens (    7.60 ms per token,   131.51 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    3897.18 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    4558.07 ms /   512 tokens (    8.90 ms per token,   112.33 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    4561.84 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    5365.28 ms /   512 tokens (   10.48 ms per token,    95.43 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    5379.83 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    4606.00 ms /   512 tokens (    9.00 ms per token,   111.16 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    4623.65 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    4637.86 ms /   512 tokens (    9.06 ms per token,   110.40 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    4640.47 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    3974.71 ms /   512 tokens (    7.76 ms per token,   128.81 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    3978.10 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    3640.35 ms /   512 tokens (    7.11 ms per token,   140.65 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    3642.72 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    3626.89 ms /   512 tokens (    7.08 ms per token,   141.17 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    3636.11 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    3697.18 ms /   512 tokens (    7.22 ms per token,   138.48 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    3702.62 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    3968.91 ms /   512 tokens (    7.75 ms per token,   129.00 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    3979.73 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    4075.47 ms /   512 tokens (    7.96 ms per token,   125.63 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    4093.35 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    3627.39 ms /   512 tokens (    7.08 ms per token,   141.15 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    3629.93 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    4036.26 ms /   512 tokens (    7.88 ms per token,   126.85 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    4039.15 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    6215.21 ms /   512 tokens (   12.14 ms per token,    82.38 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    6233.74 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    8273.30 ms /   512 tokens (   16.16 ms per token,    61.89 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    8302.73 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    4556.54 ms /   512 tokens (    8.90 ms per token,   112.37 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    4562.16 ms /   513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =    4953.66 ms /   512 tokens (    9.68 ms per token,   103.36 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =    4959.23 ms /   513 tokens\n"
     ]
    }
   ],
   "source": [
    "# Index\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=data,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embedding,\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rag pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " To create a window for your VisionOS application, you will need to use a graphical user interface (GUI) toolkit or framework that is compatible with VisionOS. Here are some general steps you can follow to create a basic window using Qt, which is a popular and widely-used GUI framework:\n",
      "\n",
      "1. Install Qt on your VisionOS system. You can download the open-source version of Qt from the official website (https://www.qt.io/) and follow the installation instructions for VisionOS.\n",
      "2. Create a new Qt project in your preferred IDE or text editor. You can use Qt Creator, which comes bundled with Qt, or any other IDE that supports Qt development.\n",
      "3. In your `main.cpp` file, include the necessary headers and set up the application window. Here's an example:\n",
      "\n",
      "```cpp\n",
      "#include <QApplication>\n",
      "#include <QWindow>\n",
      "\n",
      "int main(int argc, char *argv[]) {\n",
      "    QApplication a(argc, argv);\n",
      "    QWindow window;\n",
      "    window.setTitle(\"My VisionOS Application\");\n",
      "    window.show();\n",
      "\n",
      "    return a.exec();\n",
      "}\n",
      "```\n",
      "\n",
      "4. Design the user interface for your window using the Qt Designer or by writing code in `ui_mainwindow.h`. For example, you can add buttons, labels, and other widgets to your window layout.\n",
      "5. Implement the functionality of your application in response to user actions or events. For example, you can connect signals from buttons to slots that perform specific tasks.\n",
      "6. Build and run your application to see if the window appears as expected on your VisionOS system.\n",
      "\n",
      "These steps provide a basic outline for creating a window using Qt on VisionOS. Keep in mind that there may be additional considerations depending on the complexity of your application and the specific requirements of VisionOS. For more detailed instructions, you can refer to the official Qt documentation or other online resources.\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Answer the following question: {topic}\")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "ques = \"How can I create a window for my VisionOS application?\"\n",
    "response = chain.invoke({\"topic\": ques})\n",
    "print(\"\\n\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    5081.66 ms\n",
      "llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =     336.89 ms /    14 tokens (   24.06 ms per token,    41.56 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =     340.82 ms /    15 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " In VisionOS, creating a window for your application involves using SwiftUI and presenting a window with a specific style. Here's an example of how you can create a window in VisionOS:\n",
      "\n",
      "1. First, make sure you have set up your project to use SwiftUI as the UI framework. You can do this by checking the \"Use SwiftUI\" checkbox under the Interface tab when creating a new Xcode project or by converting an existing project to use SwiftUI.\n",
      "\n",
      "2. Create a new Swift file for your window, and make it conform to the `NSObject` and `NSViewControllerRepresentable` protocols:\n",
      "\n",
      "```swift\n",
      "import SwiftUI\n",
      "import AppKit\n",
      "\n",
      "struct MyWindow: NSObject, NSViewControllerRepresentable {\n",
      "    func makeNSViewController(context: NSObject) -> NSViewController {\n",
      "        let viewController = NSViewController()\n",
      "        viewController.view = NSView(frame: NSScreen.main!.frame)\n",
      "        return viewController\n",
      "    }\n",
      "\n",
      "    func updateNSViewController(_ nsViewController: inout NSViewController, _ context: Context) {\n",
      "        // Update the view controller's view here\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "3. In the `updateNSViewController()` function, create a new `NSWindowController` instance and set its content to an `NSView` that contains your SwiftUI `View`. You can use the `NSApplication.sharedApplication().keyWindow!.contentView` property to get the current window's content view and use it as the root view for your SwiftUI code:\n",
      "\n",
      "```swift\n",
      "func updateNSViewController(_ nsViewController: inout NSViewController, _ context: Context) {\n",
      "    if let window = nsViewController.window {\n",
      "        window.close()\n",
      "    }\n",
      "\n",
      "    nsViewController.window = NSWindow(contentRect: .zero,\n",
      "                                     styleMask: .borderless,\n",
      "                                     backing: .buffered,\n",
      "                                     defer: false)\n",
      "\n",
      "    nsViewController.window?.level = .floating\n",
      "    nsViewController.window?.isReleasable = false\n",
      "\n",
      "    let host = NSViewHost(rootView: AnyView(MyAppView()))\n",
      "    nsViewController.view = host.view\n",
      "\n",
      "    // Set up the window's title and size here if needed\n",
      "    nsViewController.window?.title = \"My Window\"\n",
      "    nsViewController.window?.hasShadow = false\n",
      "    nsViewController.window?.backgroundColor = NSColor.clear\n",
      "    nsViewController.window?.isOpaque = true\n",
      "\n",
      "    // Present the window here if needed\n",
      "    nsViewController.window?.open()\n",
      "}\n",
      "```\n",
      "\n",
      "4. Create a new SwiftUI `View` called `MyAppView`. This is where you'll place your application's content, such as buttons, text fields, or other custom views:\n",
      "\n",
      "```swift\n",
      "struct MyAppView: View {\n",
      "    var body: some View {\n",
      "        VStack {\n",
      "            Text(\"Hello, VisionOS!\")\n",
      "                .padding()\n",
      "\n",
      "            Button(action: { /* Handle button click here */ }) {\n",
      "                Text(\"Click me!\")\n",
      "            }\n",
      "        }\n",
      "        .frame(minWidth: 300, maxWidth: .infinity, minHeight: 200, maxHeight: .infinity)\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "5. Finally, use your custom `MyWindow` view controller in your application's user interface by creating an instance of it and presenting it as a space or a full-screen window:\n",
      "\n",
      "```swift\n",
      "openImmersiveSpace {\n",
      "    MyWindow()\n",
      "}\n",
      "```\n",
      "\n",
      "Keep in mind that this example demonstrates how to create a simple window with SwiftUI content, but you can customize the appearance and functionality of your window by adding additional features as needed.\n"
     ]
    }
   ],
   "source": [
    "# Simple RAG \n",
    "prompt = ChatPromptTemplate.from_template(\"Here are some relevant documents from the VisionOS documentation: {documents}. \\n\\\n",
    "                                          Use the above documents to answer the following question: {topic}\")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "ques = \"How can I create a window for my VisionOS application?\"\n",
    "response = chain.invoke({\"topic\": ques, \"documents\": retriever.get_relevant_documents(ques)})\n",
    "print(\"\\n\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
